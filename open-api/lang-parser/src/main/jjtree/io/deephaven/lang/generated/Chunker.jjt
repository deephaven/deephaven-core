options {
    STATIC = false;

    DEBUG_PARSER=false;
    DEBUG_LOOKAHEAD=false;
    DEBUG_TOKEN_MANAGER=false;

    NODE_PACKAGE="io.deephaven.lang.generated";
    MULTI=true;
    NODE_PREFIX="Chunker";
    NODE_USES_PARSER=true;
    //gives access to tokens in our visitors
    NODE_SCOPE_HOOK=true;
    VISITOR=true;
    SUPPORT_CLASS_VISIBILITY_PUBLIC=true;

    VISITOR_METHOD_NAME_INCLUDES_TYPE_NAME=true;

    JAVA_TEMPLATE_TYPE = "modern";

    TRACK_TOKENS =true;
    TOKEN_EXTENDS ="BaseToken";
    COMMON_TOKEN_ACTION=true;
}

PARSER_BEGIN(Chunker)
package io.deephaven.lang.generated;

import static io.deephaven.lang.shared.lsp.DiagnosticCode.*;
import static java.util.Collections.singletonList;

import io.deephaven.lang.api.ChunkerInvokable;
import io.deephaven.lang.api.IsScope;
import io.deephaven.lang.api.ParseState;
import io.deephaven.lang.api.ParseCancelled;
import java.util.ArrayList;
import java.util.Collections;
import java.util.HashSet;
import java.util.List;
import java.util.Set;
import java.util.Stack;
import java.util.IdentityHashMap;
import java.io.IOException;

public class Chunker implements ChunkerMixin {

    private final ParseState root = new ParseState(null);
    private volatile ParseState current = root;
    private final Stack<ParseState> stack = new Stack<ParseState>();
    private final IdentityHashMap<Node, ParseState> states = new IdentityHashMap<Node, ParseState>();
    private ChunkerInvokable invoker;

    public static void main(String[] args) throws Exception {
        final Chunker ast;
        if (args.length == 0) {
            ast = new Chunker(new StreamProvider(System.in));
        } else {
            ast = new Chunker(new StreamProvider(new java.io.StringReader(args[0])));
        }
        ast.Document();
    }

    void report(int code) {
        // no-op
    }

    void jjtreeOpenNodeScope(Node n){
        ParseState state = new ParseState(n);
        ParseState was = states.put(n, state);
        assert was == null : "State map is screwy; " + was + " and " + state + " both added for " + n;
        current.addChild(state);
        current = state;
    }

    void jjtreeCloseNodeScope(Node n){
        ParseState is = states.get(n);
        assert is != null : "State map is screwy; no entry for " + n + " found in " + states;
        current = is.finish();
    }


  public boolean isLookingAhead() {
    return jj_lookingAhead;
  }

  public Token curToken() {
    return jj_lookingAhead ? jj_scanpos : token;
  }

  @Override
  public char next() throws IOException {
    // next() is much nicer to type....
    return jj_input_stream.readChar();
  }

  @Override
  public void back(int backup, int tokenBegin) {
    jj_input_stream.backup(backup);
    if (tokenBegin != -1) {
      jj_input_stream.tokenBegin = tokenBegin;
    }
  }

  void putBackTokens(boolean clearCurrent) {
    // instead of trying to mess with the insanity of the jjt runtime state,
    // lets instead make our peeking-methods look at existing token images;
    // if there are cases where a peek method matches and an existing token is of the wrong type,
    // then we may need to fix on a case-by-case basis (adding extra "recovery productions")

    // This should at least be simplified by exposing a simple character stream,
    // which first reads the existing tokens, and then looks at the underlying input stream.
    // We may also want to behave differently when jj_lookingAhead is true. i.e. only actually
    // put tokens back when we aren't looking ahead, so we don't attempt to mutate the stack
    // until the moment we are actually creating the tokens protected by a peeker method.


    jj_ntk = -1; // erase knowledge of any existing tokens.

      jj_lastpos = jj_scanpos;
      jj_la = 1;
    if (token == null) {
      return;
    }

    final Token toPutBack = clearCurrent ? token : token.next;
    int begin;
    if (toPutBack != null) {
        begin = toPutBack.tokenBegin;
    } else {
        begin = -1;
    }
    int backup = putBack(clearCurrent ? token : token.next);
    if (clearCurrent) {
      token.next = null;
    }
    back(backup, begin);
  }

  int putBack(Token token) {
    if (token == null) {
      return 0;
    }
    // Only put back tokens we haven't already put back.
    // We want to leave the tokens attached, because
    // we may accidentally detach a legitimate token if a lookahead fails.
    if (token.detached) {
      return 0;
    }
    token.detached = true;
    int backup = putBack(token.specialToken);
    backup += token.image.length();
    Token putBack = token.next;
    token.next = null;
    return backup + putBack(putBack);
  }

  void fixState(Token token) {
    ParseState p = current;
    while (p.getSrc() != null) {
      if (p.getSrc().jjtGetLastToken() == null) {
        p.getSrc().addJunk(token);
      }
      p = p.getParent();
    }
  }

  public Token token() {
    return token;
  }

  public void checkInterrupts() {
    if (Thread.interrupted()) {
      throw new ParseCancelled();
    }
  }
}

PARSER_END(Chunker)

TOKEN_MGR_DECLS : {
    Stack stateStack = new Stack();
    boolean first;

  void backup(int n) { input_stream.backup(n); }

  void putBack(Token token, StringBuilder image, int amt) {
      input_stream.backup(amt);
      assert image.length() - amt >= 0;
      image.setLength(image.length()-amt);
      token.image = image.toString();
      token.endColumn -= amt;
  }

  public void CommonTokenAction(Token t) {
       // hm... perhaps we should also -- the specialToken length from startIndex here?
       // we handle it manually already, but will need to do more testing on comments
       // (i.e. our only SpecialTokens) later...
       t.startIndex =  getCurrentTokenAbsolutePosition();
       t.endIndex = t.startIndex + t.image.length();
       t.tokenBegin = input_stream.tokenBegin;
  }

  public int getCurrentTokenAbsolutePosition() {
      final SimpleCharStream in = input_stream;
      return jjmatchedKind == EOF && in.getTotalCharsRead() + 1 == in.getMaxNextCharInd()
          ? in.getMaxNextCharInd()
          : in.getAbsoluteTokenBegin();
  }

  public SimpleCharStream stream() {
      return input_stream;
  }

}


// we ignore slash newlines (for python's benefit)
// however, we will match actual newlines,
// since those are semantically significant in python and groovy
SKIP:
{
  "\\\n"
| "\\\r"
| "\\\r\n"
}

<DEFAULT, STR_APOS, STR_QUOTE>
TOKEN:
{
  // An internal token for any newline character
   < #NL: "\n"|"\r"|"\r\n"  >
}

<STR_APOS, STR_QUOTE>
TOKEN :
{
   <#ESCAPED_NL: "\\" [ "\n", "\r" ] > // for python, allow `\` to end a line; we will want to filter these out when appropriate...
}

<STR_APOS>
TOKEN :
{
  <#ESCAPED_APOS: "\\'" >
| <APOS_BODY: ( <ESCAPED_APOS> | <ESCAPED_NL> | ~["'", "\n", "\r"] )+ >
| <APOS_CLOSE: "'" | <NL> > : DEFAULT
}

<STR_QUOTE>
TOKEN :
{
  <#ESCAPED_QUOTE: "\\\"" >
| <QUOTE_BODY: ( <ESCAPED_QUOTE>  | <ESCAPED_NL> | ~["\"", "\n", "\r" ] )+ >
| <QUOTE_CLOSE: "\"" | <NL> > : DEFAULT
}


// Whitespace tokens; only considered in DEFAULT mode (collecting up assignment / statements).
<DEFAULT>
TOKEN:
{
   // We leave whitespace and newline tokens in the parsed ast;
   // places where whitespace can be ignored, we will simply discard the tokens.
   // This is done in preparation to properly understand python structures (where leading whitespace is significant)
   < WHITESPACE: (" " | "\t")+ >
}

// Newline must be checked for inside of strings as well...
<DEFAULT, STR_APOS, STR_QUOTE>
TOKEN:
{
  // Eat whitespace before a newline, but not after (thx python)
   < NEWLINE: ( " " | "\t" )* ( <NL> )+  >
}


// Handle comments; for now, we'll just totally ignore them,
// however, in the future, we may want to offer some kind of intelligent completion there as well.

< DEFAULT >
SPECIAL_TOKEN :
{
  // Ugh...  need to pick "//" or "#" based on groovy or python.
  // double slashes IS a valid operator in python (floor division)
  // so...  not really sure how to handle this at the tokenizer level...
  // probably makes the most sense to bifurcate DEFAULT into GROOVY and PYTHON states.
  // This is fairly straight forward for the special tokens, but we'll need to ensure
  // other token semantics are updated / possibly duplicated as well...
  <SINGLE_LINE_COMMENT: ( "//" | "#" ) (~["\n","\r"])* (<NL>)? >
}

< DEFAULT >
SPECIAL_TOKEN :
{
  < "/**" ~["/"] > { input_stream.backup(1); } : IN_JAVA_DOC_COMMENT
|
  < "/*" > : IN_MULTI_LINE_COMMENT
}

// Once in a multi-line comment, gobble up everything that isn't */
<IN_JAVA_DOC_COMMENT, IN_MULTI_LINE_COMMENT>
MORE :
{
  < ~["*"] | ( "*" ~["/"] ) >
}

// Exiting from multi-line comments
<IN_JAVA_DOC_COMMENT>
SPECIAL_TOKEN :
{
  <JAVA_DOC_COMMENT: "*/" > : DEFAULT
}

<IN_MULTI_LINE_COMMENT>
SPECIAL_TOKEN :
{
  <MULTI_LINE_COMMENT: "*/" > : DEFAULT
}

// Alright, done with whitespace and comments; now for strings:

< DEFAULT >
TOKEN:
{
  < QUOTE: "\"" > : STR_QUOTE
| < APOS: "'" > : STR_APOS
}

< DEFAULT > // TODO(later) python-only....
TOKEN:
{
  < FROM_LOCAL: "from" ( <WHITESPACE> )+ (".")+ ( <WHITESPACE> )* >
}


// Define some whitespace and universally recognized punctuation tokens
< DEFAULT >
TOKEN:
{
    // Tokens suitable for identifiers
   < NEW: "new" >
|  < EXTENDS: "extends" >
|  < IMPLEMENTS: "implements" >
|  < CLASS: ("class" | "interface" | "enum" | "@interface") >
|  < SUPER: "super" >
|  < ID:
    ["A"-"Z","a"-"z", "_", "$" ]
    (["A"-"Z","a"-"z","0"-"9", "_", "$" ])*
    >
| < #DIGIT: [ "0"-"9" ] ( [ "0"-"9", "_" ] )* >
| < #SCIENTIFIC: [ "e", "E" ] ( "-" )? <DIGIT>  >
| < NUM:
    // see https://docs.oracle.com/javase/tutorial/java/nutsandbolts/datatypes.html
    // we'll allow for all valid java formats; will consider python/groovy later
    ( "-" | "+" )?
    (
      // hex
      "0x" [ "0"-"9", "a"-"f", "A"-"F" ] ( [ "0"-"9", "a"-"f", "A"-"F", "_" ] )*
    )
    |
    (
      // binary
      "0b" ( [ "0"-"1" ] )+
    )
    |
    (
      // regular digits
      <DIGIT>
      // optional suffixes
      (
          "l" | "L" |
          ( "."
              ( <DIGIT> )?
              ( ["f", "F", "d", "D" ] | <SCIENTIFIC> )?
          )?
          | <SCIENTIFIC>
      )?
    ) >
| < #NUM_OP: "+" | "-" | "*" | "**" | "/" | "%" | "@" | "&" | "|" | "^" | ">>" | "<<" > // Consider //=
| < DOUBLE_EQ: "=" ( "=" | "~" | "=~" ) >
| < ASSIGN:  ( <NUM_OP> )? "=" ( ~[ "=", "~" ] )? > {
          // We gobble up an (optional) "extra char" to check for and avoid == and =~.
          // Here, we will put that extra char back, since we don't want it in our token
          if (image.charAt(image.length()-1) != '=') {
            putBack(matchedToken, image, 1);
          }
        }
| < INVOKE: ( <ID> ( <WHITESPACE> | <NL> )* )? "(" >
| < CLOSURE_START: "{" >
| < COLON: ":" >
| < CLOSURE_END: "}" >
| < AT: "@" >
| < ARRAY_START: "[" >
| < ARRAY_END: "]" >
| < ARROW: "->" >
| < LT: "<" >
| < GT: ">" >
| < QUEST: "?" >
| < AMP: "&" >
| < STARS: "*" ( "*" )? >
| < LOGIC:
    // we aren't concerned with correct structural use of any operators;
    // we just want to be able to gobble them up without producing syntax errors
     "!="
    | "!"
    // we may consider ternaries properly ...later.
    | ( "?" <COLON> ) // allow elvis operator (plain ? handled by <QUEST>, which we grab from productions manually)
    // explicitly not adding <COLON> as it gets special handling (b/c python and groovy use it differently)
    | ( <WHITESPACE> ( "in" | "as" | "is" | "instanceof" ) ( <WHITESPACE> | <NL> ) ) // groovy uses some words as operators
    | "*:" // groovy spread map
    | ( ".." ( "<" )? ) // groovy ranges
    | "<=>" // groovy spaceship operator
    | ( ">" ( "=" | ">" | ">>" ) )
    | ( "<" ( "=" | "<" ) )
    | ( "+" ( "+" )? )
    | ( "-" ( "-" )? )
//    | ( "*" ( "*" )? )
    | "/"
    | "%"
    | "&&"
    | ( "|" ( "|" )? )
    | "^"
    | "~"
 >
| < ACCESS:
    (
      ( <QUEST> | "*" ) // groovy
      "."
    ) |
    (
      "."
      ( <AMP> | "@" )? // more groovy
    )
>
| < TRIPLE_QUOTES:
  "\"\"\""
  (
      ( "\\\"" )
      |
      (
        ~["\""]
        | ( "\"" ~["\""] )
        | ("\"\"" ~["\""] )
      )
  )*
  ( "\"\"\"" )?
  >

| < TRIPLE_APOS:
  "'''"
  (
      ( "\\'" )
      |
      (
          ~["'"]
          | ( "'" ~["'"] )
          | ("''" ~["'"] )
      )
  )*
  ( "'''" )?
  >
| < COMMA: "," >
| < SEMI: ";" >
| < CLOSE_PAREN: ")" >
}

// Do not define new token regex here, unless they are for junk nodes!
// The actual AST nodes defined below

ChunkerDocument Document() :
{
Node n = jjtThis;
}
{
   // Grab as many statements as we can.
   EatStatements(true)
    {
      // document is done.  Fill in backlinks.
      jjtThis.jjtGetFirstToken().addBackLinks();
      return jjtThis;
    }
}

Node EatStatements(boolean persistent) #void:
{Node n = null;}
{
  (
     try {
       (
         n = Newline() |
         // TODO: pass leading whitespace into Statement.
         // We do not let Statement() gather leading Whitespace(),
         // as that could result in it being matched eagerly,
         // and we don't want to pay for LL(2+).
         // for now, we can easily search to the left of Statement()'s first token,
         // so we'll avoid any leading whitespace in any production.
         n = Whitespace() |
         n = Statement()
       )
       } catch (ParseException e) {
         // Whenever there is an unhandled parse exception,
         // gobble up the rest of the line and attach to previous node.
         if (n != null) {
           token = n.addJunk(eatJunk());
         }
         fixState(token);
         if (!persistent) {
           return n;
         }
       }
     )*
  { return n; }
}


ChunkerStatement Statement() :
{
Node expr = null; ChunkerAssign assignment = null;
Token ignore = null;
List<ChunkerAnnotation> annotations = Collections.emptyList();
checkInterrupts();
}
{
  try {
  [ annotations = Annotations() { expr = annotations.get(annotations.size() - 1); } [ Whitespace() ] ]
  (
    LOOKAHEAD( { isTypedAssign() } )
    (
      assignment = TypedAssign() { expr = assignment; }
      [ expr = Values() {
          assignment.setValue(expr);
      }]
    )
    |
    LOOKAHEAD( { isAssign() } )
    (
      assignment = Assign() { expr = assignment; }
      [ expr = Values() {
           assignment.setValue(expr);
      }] // optional to allow for `var =` as an "invalid, but likely thing we want to handle"
    )
    | LOOKAHEAD( { isClassDecl() } )
    (
      expr = JavaClassDecl()
    )
    | (
        // special handling for python `from .name` imports
        [<FROM_LOCAL>]
        expr = Values()
        [
          [ Whitespace() ]
          assignment = Assign() {
            // set the current expression as the scope to assign.
            assignment.addScope(singletonList((IsScope)expr));
          }
          [ Whitespace() ]
          [ expr = Values() ]
        ]
      )
  )
  [ Whitespace() {
    expr.adopt(jjtree.popNode());
   } ]
  ( <SEMI> {
    expr.addToken(token);
  } | <COMMA> {
    // TODO: mark this node as something that should give type information, if any, to it's sibling.
    // when we are ready for it, finding a comma token at the end of a statement should suffice to figure it out.
    // This will be useful for groovy closure and python set detection.
    expr.addToken(token);
  } | <COLON> {
    // we'll want something better than this for python ... later.
    expr.addToken(token);
  } | <CLOSURE_START> {
    ignore = token;
    back(1, token.tokenBegin);
  } | <CLOSURE_END> {
    ignore = token;
    back(1, token.tokenBegin);
  } | Newline()
    | Eof() {
      // let's keep eof's for now, since "end of the script" is a very common and important cursor position,
      // deserving of special treatment / enhanced guesses.
      // jjtree.popNode();
    } ) // optional semi-colon delimiter
   } catch (ParseException e) {
     // Whenever there is an unhandled parse exception,
     // gobble up the rest of the line and attach to previous node.
     if (expr != null) {
       token = expr.addJunk(eatJunk());
       fixState(token);
     }
   }

  {
      Token removed = jjtThis.removeToken(ignore);
      if (removed != null) {
        token = removed;
      }
      jjtThis.setAnnotations(annotations);
      return jjtThis;
  }
}

ChunkerJavaClassDecl JavaClassDecl() :
{
boolean wellFormed = false;
}
{
  // This is brutish, but we don't inspect these ast nodes at all right now...
  // and likely not for quite a while... we'd be much better off to defer to native parsers here.
  <CLASS>
  [ <WHITESPACE>
    [
      // TODO: handle well-formed-ness and associated warnings / suggestions when that fails.
      TypeDecl()
      [ <WHITESPACE> ]
      [
        <EXTENDS>
        [
          <WHITESPACE>
          TypeDecl()
          (
            [ <WHITESPACE> ]
            <COMMA>
            [ <WHITESPACE> ]
            [ TypeDecl() ]
          )*
        ]
        [ <WHITESPACE> ]
      ]
      [
        <IMPLEMENTS>
        [
          <WHITESPACE>
          TypeDecl()
          (
            [ <WHITESPACE> ]
            <COMMA>
            [ <WHITESPACE> ]
            [ TypeDecl() ]
          )*
        ]
        [ <WHITESPACE> ]
      ]
    ]
  ]
  [ <WHITESPACE> ]
  [
    (
      <CLOSURE_START>
      // TODO something which actually eats member declarations... and arbitrary `{ statementBlocks() }`
      EatStatements(false)
      [ <CLOSURE_END> {
        wellFormed = true;

      } ]
    )
    | Eof()
  ]

  {
    jjtThis.setWellFormed(wellFormed);
    return jjtThis;
  }
}

ChunkerAssign Assign() :
{}
{
  Ident()
  [ <WHITESPACE> ]
  <ASSIGN>
  [ <WHITESPACE> ]
  { return jjtThis; }
}

ChunkerTypedAssign TypedAssign() :
{}
{
  TypeDecl()
  [ <WHITESPACE> ]
  Ident()
  [ <WHITESPACE> ]
  <ASSIGN>
  [ <WHITESPACE> ]
  { return jjtThis; }
}

ChunkerTypeDecl TypeDecl():
{}
{
  <ID>
  [ <WHITESPACE> ]
  [ TypeParams() ]
  { return jjtThis; }
}

ChunkerTypeParams TypeParams() :
{ boolean wellFormed=false; }
{
  <LT>
  (
    ( <WHITESPACE> | <NEWLINE> )*
    TypeParam(true)
      ( ( <WHITESPACE> | <NEWLINE> )* <COMMA> ( <WHITESPACE> | <NEWLINE> )* TypeParam(true) )*
  )?
  [ <WHITESPACE> ]

  [ <GT> { wellFormed = true; } ]
  {
    jjtThis.setWellFormed(wellFormed);
    return jjtThis;
  }
}

ChunkerTypeParam TypeParam(boolean canWildcard) :
{ boolean wellFormed=false; }
{
  (
    ( <ID>
      ( <WHITESPACE> | <NEWLINE> )*
      (
        <ACCESS>
        ( <WHITESPACE> | <NEWLINE> )*
        [ <ID> ]
        ( <WHITESPACE> | <NEWLINE> )*
      )*
    )
    |
    <QUEST> {
      if (!canWildcard) {
        report(MALFORMED_TYPE_ARGUMENT);
      }
    }
  )
  ( <WHITESPACE> | <NEWLINE> )?
  (
    ( <EXTENDS> | <SUPER> )
    [ <WHITESPACE> | <NEWLINE> ]
    ( <ID> ( <ACCESS> [ <ID> ] )*  )
    [ TypeParams() ]
    (
      <AMP>
      [ <ID> [ TypeParams() ] ]
    )*
  )?
  {
    jjtThis.setWellFormed(wellFormed);
    return jjtThis;
  }
}

ChunkerIdent Ident() :
{}
{
  <ID>
  { return jjtThis; }
}

ChunkerNum Num() :
{}
{
  <NUM>
  { return jjtThis; }
}

ChunkerWhitespace Whitespace() :
{}
{
  <WHITESPACE>
  { return jjtThis; }
}

ChunkerMethodName MethodName() :
{}
{
  <INVOKE>
  { return jjtThis; }
}

ChunkerNewline Newline() :
{}
{
  <NEWLINE>
  { return jjtThis; }
}

ChunkerNew New() :
{
boolean wellFormed = false;
String name = null;
ChunkerInvokable parent = invoker;
List<IsScope> scope = null;
}
{
  <NEW> <WHITESPACE> [ TypeParams() ] [ scope = Scope() { jjtThis.addScope(scope); } ] [ <WHITESPACE> ] [
   (
       LOOKAHEAD( { isTypedInvoke(true) } )
       (
        <ID> { name = token.image; }
        [ <WHITESPACE> ]
        TypeParams()
        [ <WHITESPACE> ]
        MethodName() {
           name += "." + token.image.substring(0, token.image.length()-1);
        }
       )
       |
       MethodName() {
         // shave off the opening (
         name = token.image.substring(0, token.image.length()-1);
       }
     )
     [ Whitespace() ]
     { invoker = jjtThis; }
     [ MethodArguments(jjtThis) ]
     { invoker = parent; }
     try {
     (
        <CLOSE_PAREN> { wellFormed = true; }
        | Newline() {
          // we want to let newline end the final statement of source,
          // but we don't actually want to keep the token; that will be needed
          // to finish a not-the-last statement in a block of source.
          jjtThis.setWellFormed(false);
          putBackTokens(true);
          token.next = null;
          jjtree.popNode();
        }
        | Eof() {
          wellFormed = false;
        }

     )
     } catch (ParseException e) {
       // This invocation is malformed; recover here so we can continue
       Node node = jjtree.nodeArity() > 0 ? jjtree.peekNode() : jjtThis;
       Token junk = eatJunk();
       node.addToken(junk);
     }
   ]
  {
  if (name == null) { wellFormed = false; }
  jjtThis.setName(name);
  jjtThis.setWellFormed(wellFormed);
  return jjtThis;
  }
}

Node maybeBin(Node src) #void:
{
      ChunkerBinaryExpression result;
      assert src == jjtree.peekNode();
      jjtree.popNode();
}
{
  result = BinaryExpression(src)
  {
    if (result.getJoiner() == null && result.getRight() == null) {
      jjtree.pushNode(src);
      return src;
    }
    return result.rescope(null);
  }
}

// Forms a chain of whitespace-separated values;
// anything that actually matches in here is likely either
// malformed, or deserving of it's own production
// (but, for now, we're being extremely lax, so
// the parser can at least survive valid source that it
// simply does not understand well enough yet).
Node Values() #void:
{
  Node value;
  ChunkerWhitespace ws = null;
}
{
  (
    value = Expression()
    [ ws = Whitespace() {
        jjtree.popNode();
    }]
    ( value = maybeBin(value) {
        if (ws != null) {
          value.insertChild(ws, 1);
          ws = null;
        }
     }
      [ ws = Whitespace() {
        jjtree.popNode();
      }]
    )*
  )
    {
    if (ws != null) {
      jjtree.pushNode(ws);
    }
    return value;
    }
}

Node MethodArg() #void:
{ Node value; }
{

  (
    LOOKAHEAD( { isPythonAnnotated() } )
    ( value = Ident() <COLON> {
      value.addToken(token);
     } )
    |
    value = Values()
  )

  {
    return value;
  }
}
void MethodArguments(ChunkerInvokable invokable) #void:
{ Node value; ChunkerAssign assign; }
{

    // handle argument lists
    [ <STARS>
      [ Whitespace() ]
    ]
    value = MethodArg() {
      invokable.addArgument(value);
    }
    // once there is an unmatched open paren, eat both newlines and whitespace
    ( Whitespace() | Newline() )*
    (
      LOOKAHEAD( { isAssign() } )
      assign = Assign() [ value = Values() {
          assign.setValue(value);
      }]
    )?
    ( Whitespace() | Newline() )*
    (
      <COMMA>
      ( Whitespace() | Newline() )*
      [ <STARS> ]
      ( Whitespace() | Newline() )*
      [
        value = MethodArg() {
          invokable.addArgument(value);
        }
        ( Whitespace() | Newline() )*
      ]
   )*
}

List<IsScope> Scope() #void:
{
  ChunkerIdent addTo;
  ChunkerTypeParams typeParams;
  List<IsScope> sub, result = new ArrayList();
}
{
    LOOKAHEAD( { isScope() } )
    (
      addTo = Ident() {
        // hm, should probably pop this node, and force callers to always stash the actual nodes on something.
       result.add(addTo);
       jjtree.popNode();
      }
      // handle type argument lists
      [ typeParams = TypeParams() {
        addTo.setTypeParams(typeParams);
        // we are eating these TypeParams, so remove them from the stack.
        jjtree.popNode();
      } ]
      <ACCESS> {
        // add this to the Ident that we'll be returning.
        // We should maybe have a different subtype for this...
        addTo.addToken(token);
      }
      [ sub = Scope() {
        result.addAll(sub);
      }]
    )
    {
      return result;
    }

}

List<ChunkerAnnotation> Annotations() #void:
{
  ChunkerAnnotation anno;
  List<ChunkerAnnotation> result = new ArrayList();
}
{
  (
    ( anno = Annotation() {
        result.add(anno);
    } )+
  )
  {
    return result;
  }
}

ChunkerAnnotation Annotation():
{
  boolean wellFormed = false;
}
{
  (
    <AT> [ Ident() {
      wellFormed = true;
    } ]
    [ Whitespace() ]
    [ Invoke() ]
    // TODO: if python, _require_ a newline for each decorator
    ( Whitespace() | Newline() )*
  )
  { return jjtThis; }
}

ChunkerInvoke Invoke():
{
  boolean wellFormed = false;
  String name;
  ChunkerInvokable parent = invoker;
}
{
  (
    LOOKAHEAD( { isTypedInvoke(false) } )
    (
     TypeParams()
     [ <WHITESPACE> ]
     MethodName() { name = token.image.substring(0, token.image.length()-1); }
    )
    |
    MethodName() {
      // shave off the opening (
      name = token.image.substring(0, token.image.length()-1);
    }
  )
  ( Whitespace() | Newline() )*

  { invoker = jjtThis; }
  [ MethodArguments(jjtThis) ]
  {
    if (parent != null) {
   //   jjtThis.addScope(parent);
    }
    invoker = parent;
  }
  try {
    (
      (
        <CLOSE_PAREN> {
          wellFormed = true;
        }
        // technically, this should be reserved only for method declarations, not invocations,
        // but we currently are not differentiating, and are generally allowing all malformed syntax,
        // so, here it goes...
        [ <WHITESPACE> ]
        [
          <ARROW>
          [ Values() ]
          {
            wellFormed = false;
          }
          [ <COLON> {
            wellFormed = true;
          } ]
        ]
      )
      | Newline() {
        // we want to let newline end the final statement of source,
        // but we don't actually want to keep the token; that will be needed
        // to finish a not-the-last statement in a block of source.
        jjtThis.setWellFormed(false);
      }
      | Eof() {
       wellFormed = false;
     }
    )
  } catch (ParseException e) {
     // This invocation is malformed; recover here so we can continue
     Node node = jjtree.nodeArity() > 0 ? jjtree.peekNode() : jjtThis;
     Token junk = eatJunk();
     node.addToken(junk);
  }
  {
      jjtThis.setWellFormed(wellFormed);
      jjtThis.setName(name);
      return jjtThis;
  }
}

ChunkerParam Param():
{
  List<IsScope> scope;
  Node value; ChunkerAssign assign;

}
{
  (
    [
      LOOKAHEAD( { isScope() } )
      scope = Scope() {
        for (IsScope ident : scope) {
          jjtThis.addChild(ident);
        }
      }
    ]
    Ident()
    [ <WHITESPACE> ]
    [ <COLON> // python support
        Values()
    ]
    [ TypeParams() ]
    [ <WHITESPACE> ]
    [ Array() ]
    [
      <WHITESPACE>
      [
         (
           LOOKAHEAD( { isAssign() } )
           // try to gobble up assigns first...
           assign = Assign()
           ( <WHITESPACE> | <NEWLINE> )*
           [ value = Expression() {
             assign.setValue(value);
           }]
         )
           // settle for a plain identifier
         | Ident()
      ]
    ]
    [ <WHITESPACE> ]
  )
  {return jjtThis;}
}

ChunkerClosure Closure():
{
  boolean wellFormed = false, hasType = false, hadComma = false;
  Node n = null;
  List<IsScope> scope;
  List<ChunkerParam> params;
}
{
  <CLOSURE_START>
    // TODO: consider python dictionaries before getting here (i.e. make a method that peeks for dictionary syntax)
  ( Whitespace() | Newline() )*
  [
    LOOKAHEAD({ isParamList() })
    n = ClosureParams() [ <ARROW> ]
  ]
  ( Whitespace() | Newline() )*
   EatStatements(false)
  ( Whitespace() | Newline() )*

  try {
    (
      (
        <CLOSURE_END> { wellFormed = true; }
        [ Whitespace() {
          jjtree.popNode();
         }]
        [ Invoke() ]
      )
      | Eof() {
        jjtThis.setWellFormed(false);
      }
    )
  } catch (ParseException e) {
     // This invocation is malformed; recover here so we can continue
     Node node = jjtree.nodeArity() > 0 ? jjtree.peekNode() : jjtThis;
     Token junk = eatJunk();
     node.addToken(junk);
  }
  {
      jjtThis.setWellFormed(wellFormed);
      return jjtThis;
  }
}

Node ClosureParams() #void:
{Node n = null;}
{
    try {
      n = Param()
      (
        <COMMA>
        ( <WHITESPACE> | <NEWLINE> )*
        n = Param()
      )*
    } catch (ParseException ignored) {
      // any matched tokens should be put back for us...
    }

  { return n; }
}


ChunkerArray Array():
{
  boolean wellFormed = false;
  Node n = null;
}
{
  <ARRAY_START>
  // TODO: consider python list comprehension here
  ( Whitespace() | Newline() )*
  [ MethodArguments(jjtThis) ]
  ( Whitespace() | Newline() )*

  try {
    (
      <ARRAY_END> { wellFormed = true; }
      | Eof() {
        wellFormed = false;
      }
    )
  } catch (ParseException e) {
     // This invocation is malformed; recover here so we can continue
     Node node = jjtree.nodeArity() > 0 ? jjtree.peekNode() : jjtThis;
     Token junk = eatJunk();
     node.addToken(junk);
  }
  {
      jjtThis.setWellFormed(wellFormed);
      return jjtThis;
  }
}

Node Expression() #void:
{
    Node expr = null, expr2 = null, anchor = null;
    String name;
    ChunkerBinaryExpression bin = null;
    ChunkerWhitespace ws = null;
    ChunkerAssign assign = null;
    boolean wellFormed = false;
}
{
  (
    (
      // | expr = ClassDef()
      // | expr = FuncDef() // more python-y stuff...
      (
        expr = Closure()
      ) | (
        expr = Array()
      ) | (
        expr = Invoke()
      ) | (
        expr = String()
      ) | (
        expr = Num()
      ) | (
        expr = New()
      ) | (
        expr = Ident()
          [
           ws = Whitespace() {
             jjtree.popNode();
           }
           // Space-delimited expressions; this is how we ignore "keywords" like return or println
           // We should do something special when these might actually be groovy "shorthand": method calls w/out ()
           [ expr2 = Expression() {
             ChunkerBinaryExpression b = new ChunkerBinaryExpression(this, JJTBINARYEXPRESSION);
             jjtree.popNode();
             jjtree.popNode();
             b.setLeft(expr);
             b.insertChild(ws, 1);
             b.setJoiner(ws.jjtGetFirstToken());
             b.setRight(expr2);
             expr = b.rescope(null);
             jjtree.pushNode(expr);

           }]
          ]
      )
    )

    [ ws = Whitespace() {
      jjtree.popNode();
    } ]

    // after a valid expression, there may be some things to chain into a more complex expression...
    [
      {
        jjtree.popNode();
      }
      bin = BinaryExpression(expr) {
        if (bin.getRight() == null && bin.getJoiner() == null) {
          if (ws != null) {
            jjtree.pushNode(ws);
          }
          bin = null;
        } else {
          if (ws != null) {
            bin.insertChild(ws, 1);
          }
          expr = bin.rescope(null);
          if (bin != expr) {
            jjtree.popNode();
            jjtree.pushNode(expr);
            bin = null;
          }
        }
      }
    ]
    [
      (
        <ASSIGN> {
          // If we saw an assign statement, then we need to make the current expression the scope of an Assign().
          assign = new ChunkerAssign(this, JJTASSIGN);
          jjtree.popNode();
          assign.addChild(bin == null ? expr : bin);
          bin = null;
          if (ws != null) {
            assign.addChild(ws);
          }
          assign.addToken(token);
          jjtree.pushNode(assign);
          expr = assign;
        }
      )
      [ <WHITESPACE> {
          assign.addToken(token);
      }]
      [ expr2 = Values() {
        assign.setValue(expr2);
        jjtree.popNode();
        assign.addChild(expr2);
      }]
    ]
  )

  {
  if (assign != null) {
    // TODO: make addChild fix tokens so we can delete this workaround
    assign.jjtSetLastToken(token);
  }
  return bin == null ? expr : bin;
  }
}

void EatBinaryWhitespace() #void:
{}
{
  LOOKAHEAD( { isBinExprAcrossNewline() } )
  ( <WHITESPACE> | <NEWLINE> )+
  {}
}

ChunkerBinaryExpression BinaryExpression(Node left) :
{
  boolean wellFormed = left.isWellFormed();
  Node right = null;
  Token joiner;
  jjtThis.setLeft(left);
//  jjtree.popNode();
}
{
  (
    // TODO: handle newline followed by ACCESS or LOGIC
    [ EatBinaryWhitespace() ]
    (
      <LOGIC> {
        if (!(token.image.equals("++") || token.image.equals("--"))) {
          wellFormed = false; // if there is an expression, it will be reset to true...
        }
        joiner = token;
        jjtThis.setJoiner(joiner);
      }
      | <ACCESS> {
        wellFormed = false; // not legal to have this w/out a followup expression
        joiner = token;
        jjtThis.setJoiner(joiner);
      }
      | <STARS> {
        wellFormed = false; // not legal to have this w/out a followup expression
        joiner = token;
        jjtThis.setJoiner(joiner);
      }
      | <DOUBLE_EQ> {
        wellFormed = false; // not legal to have this w/out a followup expression
        joiner = token;
        jjtThis.setJoiner(joiner);
      }
      | <AMP> {
        wellFormed = false; // not legal to have this w/out a followup expression
        joiner = token;
        jjtThis.setJoiner(joiner);
      }
      | <GT> {
        wellFormed = false; // not legal to have this w/out a followup expression
        joiner = token;
        jjtThis.setJoiner(joiner);
      }
      | <LT> {
        wellFormed = false; // not legal to have this w/out a followup expression
        joiner = token;
        jjtThis.setJoiner(joiner);
      }
      | <ID> {
        joiner = token;
        jjtThis.setJoiner(joiner);
      }
      | <COLON> {
        joiner = token;
        jjtThis.setJoiner(joiner);
      }
      | right = Array() {


        ChunkerBinaryExpression b = new ChunkerBinaryExpression(this, JJTBINARYEXPRESSION);
        jjtree.popNode();
        b.setLeft(left);
        // no joiner when we're mashing a trailing [] onto an expression (optional parens are troublesome)
        b.setRight(right);
        left = b;
        right = null;
        jjtThis.setLeft(b);
        wellFormed = left.isWellFormed();
      }
    )
    [ <WHITESPACE> ]

    // recurse into the "any valid value" production.
    [ right = Expression() {
      wellFormed = left.isWellFormed();
      jjtThis.setRight(right);
      Node maybeWs = jjtree.popNode();
      if (maybeWs instanceof ChunkerWhitespace) {
        Node next = jjtree.popNode();
        assert next == right;
        jjtree.pushNode(maybeWs);
      }
    }]

    [ <WHITESPACE> ]
  )
{
    // TODO: transform <ASSIGN> types to scopes...
    jjtThis.setWellFormed(wellFormed);
    return jjtThis;
}
}


ChunkerString String() :
{
boolean wellFormed = false;
StringBuilder b = new StringBuilder();
String quoteType;
}
{
  (
    (
      <QUOTE>
      {
        quoteType = token.image;
        wellFormed = false;
      }
      [
        [ <QUOTE_BODY> { b.append(token.image); } ]
        (
          Newline() {
            // TODO: take a parameter to this production that controls
            // whether we simply absorb the newlines, or form a malformed ast node.
            jjtThis.setWellFormed(false);
            jjtree.popNode();
            putBackTokens(true);
            token.next = null;
          }
          | Eof() {
            wellFormed = false;
            jjtree.popNode();
          }
          | <QUOTE_CLOSE> {
            wellFormed = "\"".equals(token.image);
            if (!wellFormed) {
              back(token.image.length(), -1);
            }
          }
        )
      ]
    )
    |
    (
      <APOS> { quoteType = token.image; }
      {
       wellFormed = false;
       }
      [
        ( <APOS_BODY> {
          b.append(token.image);
        } )*
        (
         Newline() {
           // TODO: take a parameter to this production that controls
           // whether we simply absorb the newlines, or form a malformed ast node.
           jjtThis.setWellFormed(false);
           jjtree.popNode();
           putBackTokens(true);
           token.next = null;
         }
         | Eof() {
           wellFormed = false;
           jjtree.popNode();
          }
         | <APOS_CLOSE> {
           wellFormed = "'".equals(token.image);
           if (!wellFormed) {
             back(token.image.length(), -1);
           }
         }
        )
      ]
    )
  )
  {
    jjtThis.initialize(quoteType, b.toString(), wellFormed);
    return jjtThis;
  }
}

// This is here so we can easily Eof() { jjtree.popNode(); } to discard eof tokens
ChunkerEof Eof():
{}
{
  <EOF>
  { return jjtThis; }
}
