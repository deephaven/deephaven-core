{
 "className": "io.deephaven.kafka.CdcTools",
 "methods": {
  "cdcKeyAvroSchemaName": "Build the default Key schema name for a CDC Stream, given server name, database name and table name\n\n:param serverName: (java.lang.String) - The server name\n:param dbName: (java.lang.String) - The database name\n:param tableName: (java.lang.String) - The table name\n:return: (java.lang.String) The default Key schema name for a CDC Stream given inputs.",
  "cdcLongSpec": "**Incompatible overloads text - text from the first overload:**\n\nCreate a CdcSpec opaque object (necessary for one argument in a call to consume*ToTable) via explicitly\n specifying all configuration options.\n\n*Overload 1*  \n  :param topic: (java.lang.String) - The Kafka topic for the CDC events associated to the desired table data.\n  :param keySchemaName: (java.lang.String) - The schema name for the Key Kafka field in the CDC events for the topic. This schema should\n          include definitions for the columns forming the PRIMARY KEY of the underlying table.\n  :param valueSchemaName: (java.lang.String) - The schema name for the Value Kafka field in the CDC events for the topic. This schema\n          should include definitions for all the columns of the underlying table.\n  :return: (io.deephaven.kafka.CdcTools.CdcSpec) A CdcSpec object corresponding to the inputs; schema versions are implied to be latest.\n  \n*Overload 2*  \n  :param topic: (java.lang.String) - The Kafka topic for the CDC events associated to the desired table data.\n  :param keySchemaName: (java.lang.String) - The schema name for the Key Kafka field in the CDC events for the topic. This schema should\n          include definitions for the columns forming the PRIMARY KEY of the underlying table.\n  :param keySchemaVersion: java.lang.String\n  :param valueSchemaName: (java.lang.String) - The schema name for the Value Kafka field in the CDC events for the topic. This schema\n          should include definitions for all the columns of the underlying table.\n  :param valueSchemaVersion: (java.lang.String) - The version for the Value schema to look up in schema server.\n  :return: (io.deephaven.kafka.CdcTools.CdcSpec) A CdcSpec object corresponding to the inputs.",
  "cdcShortSpec": "Create a CdcSpec opaque object (necessary for one argument in a call to consume*ToTable) in the debezium\n style, specifying server name, database name and table name. The topic name, and key and value schema names are\n implied by convention:\n \n* Topic is the concatenation of the arguments using \".\" as separator.\n* Key schema name is topic with a \"-key\" suffix added.\n* Value schema name is topic with a \"-value\" suffix added.\n\n\n:param serverName: (java.lang.String) - The server name\n:param dbName: (java.lang.String) - The database name\n:param tableName: (java.lang.String) - The table name\n:return: (io.deephaven.kafka.CdcTools.CdcSpec) A CdcSpec object corresponding to the inputs.",
  "cdcTopicName": "Build the default CDC topic name given server name, database name and table name\n\n:param serverName: (java.lang.String) - The server name\n:param dbName: (java.lang.String) - The database name\n:param tableName: (java.lang.String) - The table name\n:return: (java.lang.String) The default CDC topic name given inputs.",
  "cdcValueAvroSchemaName": "Build the default Value schema name for a CDC Stream, given server name, database name and table name\n\n:param serverName: (java.lang.String) - The server name\n:param dbName: (java.lang.String) - The database name\n:param tableName: (java.lang.String) - The table name\n:return: (java.lang.String) The default Value schema name for a CDC Stream given inputs.",
  "consumeRawToTable": ":param kafkaProperties: java.util.Properties\n:param cdcSpec: io.deephaven.kafka.CdcTools.CdcSpec\n:param partitionFilter: java.util.function.IntPredicate\n:param tableType: io.deephaven.kafka.KafkaTools.TableType\n:return: io.deephaven.engine.table.Table",
  "consumeToTable": "Consume from a CDC Kafka Event Stream to a DHC ticking table, recreating the underlying database table.\n\n*Overload 1*  \n  :param kafkaProperties: (java.util.Properties) - Properties to configure the associated kafka consumer and also the resulting table. Passed\n          to the org.apache.kafka.clients.consumer.KafkaConsumer constructor; pass any KafkaConsumer specific\n          desired configuration here. Note this should include the relevant property for a schema server URL where\n          the key and/or value Avro necessary schemas are stored.\n  :param cdcSpec: (io.deephaven.kafka.CdcTools.CdcSpec) - A CdcSpec opaque object specifying the CDC Stream. Can be obtained from calling the\n          cdcSpec static factory method.\n  :param partitionFilter: (java.util.function.IntPredicate) - A function specifying the desired initial offset for each partition consumed The\n          convenience constant KafkaTools.ALL_PARTITIONS is defined to facilitate requesting all partitions.\n  :return: (io.deephaven.engine.table.Table) A Deephaven live table for underlying database table tracked by the CDC Stream\n  \n*Overload 2*  \n  :param kafkaProperties: (java.util.Properties) - Properties to configure the associated kafka consumer and also the resulting table. Passed\n          to the org.apache.kafka.clients.consumer.KafkaConsumer constructor; pass any KafkaConsumer specific\n          desired configuration here. Note this should include the relevant property for a schema server URL where\n          the key and/or value Avro necessary schemas are stored.\n  :param cdcSpec: (io.deephaven.kafka.CdcTools.CdcSpec) - A CdcSpec opaque object specifying the CDC Stream. Can be obtained from calling the\n          cdcSpec static factory method.\n  :param partitionFilter: (java.util.function.IntPredicate) - A function specifying the desired initial offset for each partition consumed The\n          convenience constant KafkaTools.ALL_PARTITIONS is defined to facilitate requesting all partitions.\n  :param asStreamTable: (boolean) - If true, return a stream table of row changes with an added 'op' column including the CDC\n          operation affecting the row.\n  :param dropColumns: (java.util.Collection<java.lang.String>) - Collection of column names that will be dropped from the resulting table; null for none. Note\n          that only columns not included in the primary key can be dropped at this stage; you can chain a drop\n          column operation after this call if you need to drop primary key columns.\n  :return: (io.deephaven.engine.table.Table) A Deephaven live table for underlying database table tracked by the CDC Stream"
 },
 "path": "io.deephaven.kafka.CdcTools",
 "text": "Utility class with methods to support consuming from a Change Data Capture (CDC) Kafka stream (as, eg, produced by\n Debezium) to a Deephaven table.",
 "typeName": "class"
}