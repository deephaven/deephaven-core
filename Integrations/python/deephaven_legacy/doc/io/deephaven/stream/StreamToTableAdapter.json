{
 "className": "io.deephaven.stream.StreamToTableAdapter",
 "methods": {
  "accept": "Accept a batch of rows splayed across per-column chunks of values.\n\n \n Ownership of data passes to the consumer, which must be sure to\n close each chunk when it's no longer needed.\n\n \n Implementations will generally have a mechanism for determining the expected number and type of input chunks, but\n this is not dictated at the interface level.\n\n:param data: (io.deephaven.chunk.WritableChunk<io.deephaven.chunk.attributes.Values>...) - Per-column chunks of values. Must all have the same\n        size.",
  "acceptFailure": "Report an error while processing the stream.\n\n:param cause: (java.lang.Exception) - the cause of the error",
  "chunkTypeForIndex": "Return the ChunkType for a given column index.\n\n:param idx: (int) - the column index to get the ChunkType for\n:return: (io.deephaven.chunk.ChunkType) the ChunkType for the specified column",
  "makeChunksForDefinition": "**Incompatible overloads text - text from the first overload:**\n\nCreate an array of chunks suitable for passing to our accept method.\n\n*Overload 1*  \n  :param size: (int) - the size of the chunks\n  :return: (io.deephaven.chunk.WritableChunk[]) an array of writable chunks\n  \n*Overload 2*  \n  :param definition: (io.deephaven.engine.table.TableDefinition) - the definition to make chunks for\n  :param size: (int) - the size of the returned chunks\n  :return: (io.deephaven.chunk.WritableChunk[]) an array of writable chunks",
  "setShutdownCallback": "Set a callback to be invoked when this StreamToTableAdapter will no longer deliver new data to downstream\n consumers.\n\n:param shutdownCallback: (java.lang.Runnable) - The callback",
  "table": "Return the stream table that this adapter is producing.\n\n:return: (io.deephaven.engine.table.Table) the resultant stream table"
 },
 "path": "io.deephaven.stream.StreamToTableAdapter",
 "text": "Adapter for converting streams of data into columnar Deephaven tables.",
 "typeName": "class"
}