{
 "className": "io.deephaven.engine.table.impl.by.StreamFirstChunkedOperator",
 "methods": {
  "addChunk": "Aggregate a chunk of data into the result columns.\n\n*Overload 1*  \n  :param bucketedContext: (io.deephaven.engine.table.impl.by.IterativeChunkedAggregationOperator.BucketedContext) - the operator-specific context\n  :param values: (io.deephaven.chunk.Chunk<? extendsio.deephaven.chunk.attributes.Values>) - a chunk of values to aggregate\n  :param inputRowKeys: (io.deephaven.chunk.LongChunk<? extendsio.deephaven.engine.rowset.chunkattributes.RowKeys>) - the input row keys, in post-shift space\n  :param destinations: (io.deephaven.chunk.IntChunk<io.deephaven.engine.rowset.chunkattributes.RowKeys>) - the destinations in resultColumn to aggregate into, parallel with startPositions and length\n  :param startPositions: (io.deephaven.chunk.IntChunk<io.deephaven.chunk.attributes.ChunkPositions>) - the starting positions in the chunk for each destination\n  :param length: (io.deephaven.chunk.IntChunk<io.deephaven.chunk.attributes.ChunkLengths>) - the number of values in the chunk for each destination\n  :param stateModified: (io.deephaven.chunk.WritableBooleanChunk<io.deephaven.chunk.attributes.Values>) - a boolean output array, parallel to destinations, which is set to true if the corresponding\n          destination has been modified\n  \n*Overload 2*  \n  :param context: (io.deephaven.engine.table.impl.by.IterativeChunkedAggregationOperator.SingletonContext) - the operator-specific context\n  :param chunkSize: (int) - the size of the addition\n  :param values: (io.deephaven.chunk.Chunk<? extendsio.deephaven.chunk.attributes.Values>) - the values to aggregate\n  :param inputRowKeys: (io.deephaven.chunk.LongChunk<? extendsio.deephaven.engine.rowset.chunkattributes.RowKeys>) - the input row keys, in post-shift space\n  :param destination: (long) - the destination in the result columns\n  :return: (boolean) true if the state was modified, false otherwise",
  "addRowSet": ":param context: io.deephaven.engine.table.impl.by.IterativeChunkedAggregationOperator.SingletonContext\n:param rowSet: io.deephaven.engine.rowset.RowSet\n:param destination: long\n:return: boolean",
  "ensureCapacity": "Ensure that this operator can handle destinations up to tableSize - 1.\n\n:param tableSize: (long) - the new size of the table",
  "makeBucketedContext": "Make a IterativeChunkedAggregationOperator.BucketedContext suitable for this operator if necessary.\n\n:param size: (int) - The maximum size of input chunks that will be used with the result context\n:return: (io.deephaven.engine.table.impl.by.IterativeChunkedAggregationOperator.BucketedContext) A new IterativeChunkedAggregationOperator.BucketedContext, or null if none is necessary",
  "propagateInitialState": "Perform any internal state keeping needed for destinations that were added during initialization.\n\n:param resultTable: (io.deephaven.engine.table.impl.QueryTable) - The result QueryTable after initialization",
  "propagateUpdates": "Perform any internal state keeping needed for destinations that were added (went from 0 keys to > 0), removed\n (went from > 0 keys to 0), or modified (keys added or removed, or keys modified) by this iteration. Note that\n the arguments to this method should not be mutated in any way.\n\n:param downstream: (io.deephaven.engine.table.TableUpdate) - The downstream TableUpdate (which does not have its ModifiedColumnSet\n        finalized yet)\n:param newDestinations: (io.deephaven.engine.rowset.RowSet) - New destinations added on this update",
  "startTrackingPrevValues": "Called after initialization; when the operator's result columns must have previous tracking enabled.",
  "unchunkedRowSet": "Whether the operator can deal with an unchunked RowSet more efficiently than a chunked RowSet.\n\n:return: (boolean) true if the operator can deal with unchunked RowSets, false otherwise"
 },
 "path": "io.deephaven.engine.table.impl.by.StreamFirstChunkedOperator",
 "text": "A firstBy aggregation operator for stream tables.",
 "typeName": "class"
}