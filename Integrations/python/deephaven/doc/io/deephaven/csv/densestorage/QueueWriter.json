{
 "className": "io.deephaven.csv.densestorage.QueueWriter",
 "methods": {
  "finish": "Caller is finished writing.",
  "flush": "This supports an \"early flush\" for callers like DenseStorageWriter who want to flush all their queues\n from time to time.",
  "newReader": "Make a QueueReader corresponding to this QueueWriter. You can make as many QueueReaders as you\n want, but you should make them before you start writing data.\n\n:return: QueueWriter.TREADER"
 },
 "path": "io.deephaven.csv.densestorage.QueueWriter",
 "text": "The various QueueWriters (QueueWriter.ByteWriter, QueueWriter.IntWriter, etc.) work in tandem with their corresponding\n QueueReaders (QueueReader.ByteReader, QueueReader.IntReader, etc), forming a FIFO queue. The\n QueueWriter writes data, and the QueueReader reads that data. If the QueueReader \"catches up\", it\n will block until the QueueWriter provides more data, or indicates that it is done (via the finish() method.\n This synchronization is done at \"block\" granularity, so the QueueReader can only proceed when the QueueWriter\n has written at least a \"block\" of data or is done. We allow multiple independent QueueReaders to consume the\n same underlying data. In our implementation this is used so our type inferencer can take a second \"pass\" over the\n same input data.\n\n In our implementation the DenseStorageWriter and DenseStorageReader are built out of various\n QueueWriters and QueueReaders. This explains why the semantics of DenseStorageWriter and\n DenseStorageReader are similar to those of the underlying QueueWriters and QueueReaders.",
 "typeName": "class"
}