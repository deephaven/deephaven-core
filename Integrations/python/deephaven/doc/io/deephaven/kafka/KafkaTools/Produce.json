{
 "className": "io.deephaven.kafka.KafkaTools$Produce",
 "methods": {
  "avroSpec": "**Incompatible overloads text - text from the first overload:**\n\nAvro spec from fetching an Avro schema from a Confluent compatible Schema Server. The Properties used to\n initialize Kafka should contain the URL for the Schema Server to use under the \"schema.registry.url\"\n property.\n\n*Overload 1*  \n  :param schema: (org.apache.avro.Schema) - An Avro schema. The message will implement this schema; all fields will be populated from some\n          table column via explicit or implicit mapping.\n  :param fieldToColumnMapping: (java.util.Map<java.lang.String,java.lang.String>) - A map from Avro schema field name to column name. Any field names not included as\n          a key in the map will be mapped to columns with the same name. If null, map all fields to columns of\n          the same name.\n  :param timestampFieldName: (java.lang.String) - If not null, include a field of the given name with a publication timestamp. The\n          field with the given name should exist in the provided schema, and be of logical type timestamp\n          micros.\n  :return: (io.deephaven.kafka.KafkaTools.Produce.KeyOrValueSpec) A spec corresponding to the schema provided.\n  \n*Overload 2*  \n  :param schemaName: (java.lang.String) - The registered name for the schema on Schema Server\n  :param schemaVersion: (java.lang.String) - The version to fetch. Pass the constant AVRO_LATEST_VERSION for latest\n  :param fieldToColumnMapping: (java.util.Map<java.lang.String,java.lang.String>) - A map from Avro schema field name to column name. Any field names not included as\n          a key in the map will be mapped to columns with the same name. If null, map all fields to columns of\n          the same name.\n  :param timestampFieldName: (java.lang.String) - If not null, include a field of the given name with a publication timestamp. The\n          field with the given name should exist in the provided schema, and be of logical type timestamp\n          micros.\n  :return: (io.deephaven.kafka.KafkaTools.Produce.KeyOrValueSpec) A spec corresponding to the schema provided.",
  "ignoreSpec": "Spec to explicitly ask\n consumeToTable to ignore either key or value.\n\n:return: io.deephaven.kafka.KafkaTools.Produce.KeyOrValueSpec",
  "jsonSpec": "**Incompatible overloads text - text from the first overload:**\n\nA JSON spec from a set of column names\n\n*Overload 1*  \n  :param includeColumns: (java.lang.String[]) - An array with an entry for each column intended to be included in the JSON output. If\n          null, include all columns except those specified in excludeColumns. If includeColumns\n          is not null, excludeColumns should be null.\n  :param excludeColumns: (java.util.Set<java.lang.String>) - A set specifying column names to ommit; can only be used when  is null.\n          In this case all table columns except for the ones in excludeColumns will be included.\n  :param columnToFieldMapping: (java.util.Map<java.lang.String,java.lang.String>) - A map from column name to JSON field name to use for that column. Any column\n          names implied by earlier arguments not included as a key in the map will be mapped to JSON fields of\n          the same name. If null, map all columns to fields of the same name.\n  :param nestedObjectDelimiter: (java.lang.String) - if nested JSON fields are desired, the field separator that is used for the\n          fieldNames parameter, or null for no nesting. For instance, if a particular column should be mapped to\n          JSON field X nested inside field Y, the corresponding field name value for the column\n          key in the columnToFieldMapping map can be the string \"X.Y\", in which case the value\n          for nestedObjectDelimiter should be {code \".\"}\n  :param outputNulls: (boolean) - If false, omit fields with a null value.\n  :param timestampFieldName: (java.lang.String) - If not null, include a field of the given name with a publication timestamp.\n  :return: (io.deephaven.kafka.KafkaTools.Produce.KeyOrValueSpec) A JSON spec for the given inputs.\n  \n*Overload 2*  \n  :param includeColumns: (java.lang.String[]) - An array with an entry for each column intended to be included in the JSON output. If\n          null, include all columns except those specified in excludeColumns. If includeColumns\n          is not null, excludeColumns should be null.\n  :param excludeColumns: (java.util.Set<java.lang.String>) - A set specifying column names to ommit; can only be used when  is null.\n          In this case all table columns except for the ones in excludeColumns will be included.\n  :param columnToFieldMapping: (java.util.Map<java.lang.String,java.lang.String>) - A map from column name to JSON field name to use for that column. Any column\n          names implied by earlier arguments not included as a key in the map will be mapped to JSON fields of\n          the same name. If null, map all columns to fields of the same name.\n  :return: (io.deephaven.kafka.KafkaTools.Produce.KeyOrValueSpec) A JSON spec for the given inputs.",
  "simpleSpec": "A simple spec for sending one column as either key or value in a Kafka message.\n\n:param columnName: (java.lang.String) - The name of the column to include.\n:return: (io.deephaven.kafka.KafkaTools.Produce.KeyOrValueSpec) A simple spec for the given input."
 },
 "path": "io.deephaven.kafka.KafkaTools.Produce",
 "typeName": "class"
}