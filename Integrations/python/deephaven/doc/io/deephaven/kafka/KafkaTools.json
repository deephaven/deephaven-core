{
 "className": "io.deephaven.kafka.KafkaTools",
 "methods": {
  "avroSchemaToColumnDefinitions": "*Overload 1*  \n  :param columns: java.util.List<io.deephaven.db.tables.ColumnDefinition>\n  :param mappedOut: java.util.Map<java.lang.String,java.lang.String>\n  :param schema: org.apache.avro.Schema\n  :param fieldNameToColumnName: java.util.function.Function<java.lang.String,java.lang.String>\n  \n*Overload 2*  \n  :param columns: java.util.List<io.deephaven.db.tables.ColumnDefinition>\n  :param schema: org.apache.avro.Schema\n  :param fieldNameToColumnName: java.util.function.Function<java.lang.String,java.lang.String>\n  \n*Overload 3*  \n  :param columns: java.util.List<io.deephaven.db.tables.ColumnDefinition>\n  :param schema: org.apache.avro.Schema",
  "avroSpec": "*Overload 1*  \n  :param schema: org.apache.avro.Schema\n  :param fieldNameToColumnName: java.util.function.Function<java.lang.String,java.lang.String>\n  :return: io.deephaven.kafka.KafkaTools.KeyOrValueSpec\n  \n*Overload 2*  \n  :param schema: org.apache.avro.Schema\n  :return: io.deephaven.kafka.KafkaTools.KeyOrValueSpec\n  \n*Overload 3*  \n  :param schemaName: java.lang.String\n  :param schemaVersion: java.lang.String\n  :param fieldNameToColumnName: java.util.function.Function<java.lang.String,java.lang.String>\n  :return: io.deephaven.kafka.KafkaTools.KeyOrValueSpec\n  \n*Overload 4*  \n  :param schemaName: java.lang.String\n  :param fieldNameToColumnName: java.util.function.Function<java.lang.String,java.lang.String>\n  :return: io.deephaven.kafka.KafkaTools.KeyOrValueSpec\n  \n*Overload 5*  \n  :param schemaName: java.lang.String\n  :param schemaVersion: java.lang.String\n  :return: io.deephaven.kafka.KafkaTools.KeyOrValueSpec\n  \n*Overload 6*  \n  :param schemaName: java.lang.String\n  :return: io.deephaven.kafka.KafkaTools.KeyOrValueSpec",
  "consumeToTable": "Consume from Kafka to a Deephaven table.\n\n:param kafkaConsumerProperties: (java.util.Properties) - Properties to configure this table and also to be passed to create the KafkaConsumer\n:param topic: (java.lang.String) - Kafka topic name\n:param partitionFilter: (java.util.function.IntPredicate) - A predicate returning true for the partitions to consume\n:param partitionToInitialOffset: (java.util.function.IntToLongFunction) - A function specifying the desired initial offset for each partition consumed\n:param keySpec: (io.deephaven.kafka.KafkaTools.KeyOrValueSpec) - Conversion specification for Kafka record keys\n:param valueSpec: (io.deephaven.kafka.KafkaTools.KeyOrValueSpec) - Conversion specification for Kafka record values\n:param resultType: (io.deephaven.kafka.KafkaTools.TableType) - KafkaTools.TableType specifying the type of the expected result\n:return: (io.deephaven.db.tables.Table) The result table containing Kafka stream data formatted according to resultType",
  "friendlyNameToTableType": "Map \"Python-friendly\" table type name to a KafkaTools.TableType.\n\n:param typeName: (java.lang.String) - The friendly name\n:return: (io.deephaven.kafka.KafkaTools.TableType) The mapped KafkaTools.TableType",
  "getAvroSchema": "*Overload 1*  \n  :param schemaServerUrl: java.lang.String\n  :param resourceName: java.lang.String\n  :param version: java.lang.String\n  :return: org.apache.avro.Schema\n  \n*Overload 2*  \n  :param schemaServerUrl: java.lang.String\n  :param resourceName: java.lang.String\n  :return: org.apache.avro.Schema",
  "ignoreSpec": "Spec to explicitly ask\n consumeToTable\n to ignore either key or value.\n\n:return: io.deephaven.kafka.KafkaTools.KeyOrValueSpec",
  "jsonSpec": "*Overload 1*  \n  :param columnDefinitions: io.deephaven.db.tables.ColumnDefinition<?>[]\n  :param fieldNameToColumnName: java.util.Map<java.lang.String,java.lang.String>\n  :return: io.deephaven.kafka.KafkaTools.KeyOrValueSpec\n  \n*Overload 2*  \n  :param columnDefinitions: io.deephaven.db.tables.ColumnDefinition<?>[]\n  :return: io.deephaven.kafka.KafkaTools.KeyOrValueSpec",
  "partitionFilterFromArray": ":param partitions: int[]\n:return: java.util.function.IntPredicate",
  "partitionToOffsetFromParallelArrays": ":param partitions: int[]\n:param offsets: long[]\n:return: java.util.function.IntToLongFunction",
  "simpleSpec": "The types for key or value are either specified in the properties as \"key.type\" or \"value.type\",\n or deduced from the serializer classes for key or value in the provided Properties object.\n\n*Overload 1*  \n  :param columnName: java.lang.String\n  :param dataType: java.lang.Class<?>\n  :return: io.deephaven.kafka.KafkaTools.KeyOrValueSpec\n  \n*Overload 2*  \n  :param columnName: java.lang.String\n  :return: io.deephaven.kafka.KafkaTools.KeyOrValueSpec"
 },
 "path": "io.deephaven.kafka.KafkaTools",
 "typeName": "class"
}