{
 "className": "io.deephaven.kafka.KafkaTools",
 "methods": {
  "avroSchemaToColumnDefinitions": "*Overload 1*  \n  :param columns: java.util.List<io.deephaven.db.tables.ColumnDefinition>\n  :param mappedOut: java.util.Map<java.lang.String,java.lang.String>\n  :param schema: org.apache.avro.Schema\n  :param fieldNameToColumnName: java.util.function.Function<java.lang.String,java.lang.String>\n  \n*Overload 2*  \n  :param columns: java.util.List<io.deephaven.db.tables.ColumnDefinition>\n  :param schema: org.apache.avro.Schema\n  :param fieldNameToColumnName: java.util.function.Function<java.lang.String,java.lang.String>\n  \n*Overload 3*  \n  :param columns: java.util.List<io.deephaven.db.tables.ColumnDefinition>\n  :param schema: org.apache.avro.Schema",
  "avroSpec": "*Overload 1*  \n  :param schema: org.apache.avro.Schema\n  :param fieldNameToColumnName: java.util.function.Function<java.lang.String,java.lang.String>\n  :return: io.deephaven.kafka.KafkaTools.KeyOrValueSpec\n  \n*Overload 2*  \n  :param schema: org.apache.avro.Schema\n  :return: io.deephaven.kafka.KafkaTools.KeyOrValueSpec",
  "consumeToTable": "Consume from Kafka to a Deephaven streaming table.\n\n:param kafkaConsumerProperties: (java.util.Properties) - Properties to configure this table and also to be passed to create the KafkaConsumer.\n:param topic: (java.lang.String) - Kafka topic name.\n:param partitionFilter: (java.util.function.IntPredicate) - A predicate returning true for the partitions to consume.\n:param partitionToInitialOffset: (java.util.function.IntToLongFunction) - A function specifying the desired initial offset for each partition consumed.\n:param keySpec: (io.deephaven.kafka.KafkaTools.KeyOrValueSpec) - \n:param valueSpec: (io.deephaven.kafka.KafkaTools.KeyOrValueSpec) - \n:return: (io.deephaven.db.tables.Table) The streaming table where kafka events are ingested.",
  "fieldNameToColumnNameFromParallelArrays": ":param fieldNames: java.lang.String[]\n:param columnNames: java.lang.String[]\n:return: java.util.function.Function<java.lang.String,java.lang.String>",
  "getAvroSchema": ":param schemaServerUrl: java.lang.String\n:param resourceName: java.lang.String\n:param version: java.lang.String\n:return: org.apache.avro.Schema",
  "ignoreSpec": ":return: io.deephaven.kafka.KafkaTools.KeyOrValueSpec",
  "jsonSpec": "*Overload 1*  \n  :param columnDefinitions: io.deephaven.db.tables.ColumnDefinition<?>[]\n  :param fieldNameToColumnName: java.util.Map<java.lang.String,java.lang.String>\n  :return: io.deephaven.kafka.KafkaTools.KeyOrValueSpec\n  \n*Overload 2*  \n  :param columnDefinitions: io.deephaven.db.tables.ColumnDefinition<?>[]\n  :return: io.deephaven.kafka.KafkaTools.KeyOrValueSpec",
  "partitionFilterFromArray": ":param partitions: int[]\n:return: java.util.function.IntPredicate",
  "partitionToOffsetFromParallelArrays": ":param partitions: int[]\n:param offsets: long[]\n:return: java.util.function.IntToLongFunction",
  "simpleSpec": "The types for key or value are either specified in the properties as \"key.type\" or \"value.type\",\n or deduced from the serializer classes for key or value in the provided Properties object.\n\n*Overload 1*  \n  :param columnName: java.lang.String\n  :param dataType: java.lang.Class<?>\n  :return: io.deephaven.kafka.KafkaTools.KeyOrValueSpec\n  \n*Overload 2*  \n  :param columnName: java.lang.String\n  :return: io.deephaven.kafka.KafkaTools.KeyOrValueSpec"
 },
 "path": "io.deephaven.kafka.KafkaTools",
 "typeName": "class"
}