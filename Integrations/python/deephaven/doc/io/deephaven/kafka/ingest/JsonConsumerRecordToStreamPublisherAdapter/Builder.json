{
 "className": "io.deephaven.kafka.ingest.JsonConsumerRecordToStreamPublisherAdapter$Builder",
 "methods": {
  "addColumnToValueField": "Map a column to a field in the value record.\n\n:param column: (java.lang.String) - the name of the output column\n:param field: (java.lang.String) - the name of the field in the value record\n:return: (io.deephaven.kafka.ingest.JsonConsumerRecordToStreamPublisherAdapter.Builder) this builder",
  "allowMissingKeys": "If allowMissingKeys is set, then a request for a value using a key that is not found in the record\n will receive a null value. Otherwise, an exception is thrown when a key is not found in the record.\n\n:param allowMissingKeys: (boolean) - to allow quietly continuing if requested value's key is not in the current record.\n:return: (io.deephaven.kafka.ingest.JsonConsumerRecordToStreamPublisherAdapter.Builder) this builder",
  "allowNullValues": "If allowNullValues is set, then records with a null value will have their columns null filled; otherwise\n an exception is thrown on receipt of a null value.\n\n If no value fields are set, then no columns are taken from the value; so this flag has no effect.\n\n:param allowNullValues: (boolean) - if null values are allowed\n:return: (io.deephaven.kafka.ingest.JsonConsumerRecordToStreamPublisherAdapter.Builder) this builder",
  "allowUnmapped": "Allow the column with the given name to be unmapped in the output.\n\n Unmapped columns will have no setter, and will thus be null filled in the output.\n\n:param allowUnmapped: (java.lang.String) - the column name to allow to be unmapped\n:return: (io.deephaven.kafka.ingest.JsonConsumerRecordToStreamPublisherAdapter.Builder) this builder",
  "autoValueMapping": "If autoValueMapping is set, then all unused columns are mapped to a field of the same name in the generic record.\n\n:param autoValueMapping: (boolean) - if unused columns should be automatically mapped to a field of the same name\n:return: (io.deephaven.kafka.ingest.JsonConsumerRecordToStreamPublisherAdapter.Builder) this builder",
  "kafkaPartitionColumnName": "Set the name of the column which stores the Kafka partition identifier of the record.\n\n:param kafkaPartitionColumnName: (java.lang.String) - the name of the column in the output table\n:return: (io.deephaven.kafka.ingest.JsonConsumerRecordToStreamPublisherAdapter.Builder) this builder",
  "offsetColumnName": "Set the name of the column which stores the Kafka offset of the record.\n\n:param offsetColumnName: (java.lang.String) - the name of the column in the output table\n:return: (io.deephaven.kafka.ingest.JsonConsumerRecordToStreamPublisherAdapter.Builder) this builder",
  "timestampColumnName": "Set the name of the column which stores the Kafka timestamp of the record.\n\n:param timestampColumnName: (java.lang.String) - the name of the column in the output table\n:return: (io.deephaven.kafka.ingest.JsonConsumerRecordToStreamPublisherAdapter.Builder) this builder"
 },
 "path": "io.deephaven.kafka.ingest.JsonConsumerRecordToStreamPublisherAdapter.Builder",
 "text": "A builder to map key and value fields to table columns.",
 "typeName": "class"
}