{
 "className": "io.deephaven.db.tables.utils.ParquetTools",
 "methods": {
  "deleteTable": "Deletes a table on disk.\n\n:param path: (java.io.File) - path to delete",
  "readTable": "Reads in a table from disk.\n\n*Overload 1*  \n  :param location: (java.io.File) - table location; if it ends in \".parquet\" is assumed to be a single file location, otherwise is a directory.\n  :param tableDefinition: (io.deephaven.db.tables.TableDefinition) - table definition\n  :return: (io.deephaven.db.tables.Table) table\n  \n*Overload 2*  \n  :param location: java.io.File\n  :param readInstructions: io.deephaven.db.v2.parquet.ParquetInstructions\n  :param tableDefinition: io.deephaven.db.tables.TableDefinition\n  :return: io.deephaven.db.tables.Table\n  \n*Overload 3*  \n  :param sourceFilePath: (java.lang.String) - table location; if it ends in \".parquet\" is assumed to be a single file location, otherwise is a directory.\n  :return: (io.deephaven.db.tables.Table) table\n  \n*Overload 4*  \n  :param sourceFilePath: (java.io.File) - table location; if its path ends in \".parquet\" is assumed to be a single file location, otherwise is a directory.\n  :return: (io.deephaven.db.tables.Table) table",
  "setDefaultParquetCompressionCodec": "Sets the default parquet compression codec for writing parquet.\n\n:param codecName: (java.lang.String) - the codec name.",
  "writeParquetTable": "Writes a table to disk in parquet format under a given destination.  If you specify grouping columns, there\n must already be grouping information for those columns in the source.  This can be accomplished with\n .by(<grouping columns>).ungroup() or .sort(<grouping column>).\n\n:param source: (io.deephaven.db.tables.Table) - The table to write\n:param tableDefinition: (io.deephaven.db.tables.TableDefinition) - The schema for the tables to write\n:param codecName: (org.apache.parquet.hadoop.metadata.CompressionCodecName) - Compression codec to use.\n:param destinationDir: (java.io.File) - The destination path\n:param groupingColumns: (java.lang.String[]) - List of columns the tables are grouped by (the write operation will store the grouping info)",
  "writeParquetTables": "Writes tables to disk in parquet format under a given destinations.  If you specify grouping columns, there\n must already be grouping information for those columns in the sources.  This can be accomplished with\n .by(<grouping columns>).ungroup() or .sort(<grouping column>).\n\n:param sources: (io.deephaven.db.tables.Table[]) - The tables to write\n:param tableDefinition: (io.deephaven.db.tables.TableDefinition) - The common schema for all the tables to write\n:param codecName: (org.apache.parquet.hadoop.metadata.CompressionCodecName) - Compression codec to use.\n:param destinations: (java.io.File[]) - The destinations path\n:param groupingColumns: (java.lang.String[]) - List of columns the tables are grouped by (the write operation will store the grouping info)",
  "writeTable": "Write out a table to disk.\n\n*Overload 1*  \n  :param sourceTable: (io.deephaven.db.tables.Table) - source table\n  :param destPath: (java.lang.String) - destination file path; if it ends in \".parquet\", it is assumed to be a file, otherwise a directory.\n  \n*Overload 2*  \n  :param sourceTable: (io.deephaven.db.tables.Table) - source table\n  :param dest: (java.io.File) - destination; if its path ends in \".parquet\", it is assumed to be a single file location, otherwise a directory.\n  \n*Overload 3*  \n  :param sourceTable: (io.deephaven.db.tables.Table) - source table\n  :param destPath: (java.lang.String) - destination file path; if it ends in \".parquet\", it is assumed to be a file, otherwise a directory.\n  :param storageFormat: (io.deephaven.db.tables.utils.ParquetTools.StorageFormat) - Format used for storage\n  \n*Overload 4*  \n  :param sourceTable: (io.deephaven.db.tables.Table) - source table\n  :param dest: (java.io.File) - destination; if its path ends in \".parquet\", it is assumed to be a single file location, otherwise a directory.\n  :param storageFormat: (io.deephaven.db.tables.utils.ParquetTools.StorageFormat) - Format used for storage\n  \n*Overload 5*  \n  :param sourceTable: (io.deephaven.db.tables.Table) - source table\n  :param definition: (io.deephaven.db.tables.TableDefinition) - table definition.  Will be written to disk as given.\n  :param destFile: (java.io.File) - destination file; if its path ends in \".parquet\", it is assumed to be a single file location path, otherwise a directory.\n  :param storageFormat: (io.deephaven.db.tables.utils.ParquetTools.StorageFormat) - Format used for storage",
  "writeTables": "Write out tables to disk.\n\n*Overload 1*  \n  :param sources: (io.deephaven.db.tables.Table[]) - source tables\n  :param tableDefinition: (io.deephaven.db.tables.TableDefinition) - table definition\n  :param destinations: (java.io.File[]) - destinations\n  \n*Overload 2*  \n  :param sources: (io.deephaven.db.tables.Table[]) - source tables\n  :param tableDefinition: (io.deephaven.db.tables.TableDefinition) - table definition\n  :param destinations: (java.io.File[]) - destinations\n  :param storageFormat: (io.deephaven.db.tables.utils.ParquetTools.StorageFormat) - Format used for storage"
 },
 "path": "io.deephaven.db.tables.utils.ParquetTools",
 "text": "Tools for managing and manipulating tables on disk.\n\n Most users will need TableTools and not ParquetTools.",
 "typeName": "class"
}
