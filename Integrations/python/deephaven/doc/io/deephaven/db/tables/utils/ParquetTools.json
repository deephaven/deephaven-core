{
 "className": "io.deephaven.db.tables.utils.ParquetTools",
 "methods": {
  "convertSchema": "Convert schema information from a ParquetMetadata into ColumnDefinitions.\n\n:param parquetMetadata: (org.apache.parquet.hadoop.metadata.ParquetMetadata) - The ParquetMetadata to convert\n:param readInstructionsIn: (io.deephaven.db.v2.parquet.ParquetInstructions) - Input conversion ParquetInstructions\n:return: (io.deephaven.base.Pair<java.util.List<io.deephaven.db.tables.ColumnDefinition>,io.deephaven.db.v2.parquet.ParquetInstructions>) A Pair with ColumnDefinitions and adjusted ParquetInstructions",
  "deleteTable": "Deletes a table on disk.\n\n:param path: (java.io.File) - path to delete",
  "getParquetFileReader": "Make a ParquetFileReader for the supplied File.\n\n:param parquetFile: (java.io.File) - The File to read\n:return: (io.deephaven.parquet.ParquetFileReader) The new ParquetFileReader",
  "readParquetSchemaAndTable": ":param source: java.io.File\n:param readInstructionsIn: io.deephaven.db.v2.parquet.ParquetInstructions\n:param instructionsOut: org.apache.commons.lang3.mutable.MutableObject<io.deephaven.db.v2.parquet.ParquetInstructions>\n:return: io.deephaven.db.tables.Table",
  "readPartitionedTable": "Reads in a table from files discovered with locationKeyFinder using the provided table definition.\n\n:param locationKeyFinder: (io.deephaven.db.v2.locations.impl.TableLocationKeyFinder<io.deephaven.db.v2.locations.parquet.local.ParquetTableLocationKey>) - The source of location keys to include\n:param readInstructions: (io.deephaven.db.v2.parquet.ParquetInstructions) - Instructions for customizations while reading\n:param tableDefinition: (io.deephaven.db.tables.TableDefinition) - The table's definition\n:return: (io.deephaven.db.tables.Table) The table",
  "readPartitionedTableInferSchema": "Reads in a table from files discovered with locationKeyFinder using a definition built from the\n first location found, which must have non-null partition values for all partition keys.\n\n:param locationKeyFinder: (io.deephaven.db.v2.locations.impl.TableLocationKeyFinder<io.deephaven.db.v2.locations.parquet.local.ParquetTableLocationKey>) - The source of location keys to include\n:param readInstructions: (io.deephaven.db.v2.parquet.ParquetInstructions) - Instructions for customizations while reading\n:return: (io.deephaven.db.tables.Table) The table",
  "readPartitionedTableWithMetadata": "Reads in a table using metadata files found in the supplied directory.\n\n:param directory: (java.io.File) - The source of location keys to include\n:param readInstructions: (io.deephaven.db.v2.parquet.ParquetInstructions) - Instructions for customizations while reading\n:return: (io.deephaven.db.tables.Table) The table",
  "readSingleFileTable": "Reads in a table from a single parquet file using the provided table definition.\n\n:param tableLocationKey: (io.deephaven.db.v2.locations.parquet.local.ParquetTableLocationKey) - The location keys to include\n:param readInstructions: (io.deephaven.db.v2.parquet.ParquetInstructions) - Instructions for customizations while reading\n:param tableDefinition: (io.deephaven.db.tables.TableDefinition) - The table's definition\n:return: (io.deephaven.db.tables.Table) The table",
  "readTable": "Reads in a table from a single parquet, metadata file, or directory with recognized layout.\n\n*Overload 1*  \n  :param sourceFilePath: (java.lang.String) - The file or directory to examine\n  :return: (io.deephaven.db.tables.Table) table\n  \n*Overload 2*  \n  :param sourceFilePath: (java.lang.String) - The file or directory to examine\n  :param readInstructions: (io.deephaven.db.v2.parquet.ParquetInstructions) - Instructions for customizations while reading\n  :return: (io.deephaven.db.tables.Table) table\n  \n*Overload 3*  \n  :param sourceFile: (java.io.File) - The file or directory to examine\n  :return: (io.deephaven.db.tables.Table) table\n  \n*Overload 4*  \n  :param sourceFile: (java.io.File) - The file or directory to examine\n  :param readInstructions: (io.deephaven.db.v2.parquet.ParquetInstructions) - Instructions for customizations while reading\n  :return: (io.deephaven.db.tables.Table) table",
  "setDefaultCompressionCodecName": ":param compressionCodecName: java.lang.String",
  "writeParquetTables": "Writes tables to disk in parquet format to a supplied set of destinations.  If you specify grouping columns, there\n must already be grouping information for those columns in the sources.  This can be accomplished with\n .by(<grouping columns>).ungroup() or .sort(<grouping column>).\n\n:param sources: (io.deephaven.db.tables.Table[]) - The tables to write\n:param tableDefinition: (io.deephaven.db.tables.TableDefinition) - The common schema for all the tables to write\n:param writeInstructions: (io.deephaven.db.v2.parquet.ParquetInstructions) - Write instructions for customizations while writing\n:param destinations: (java.io.File[]) - The destinations paths.    Any non existing directories in the paths provided are created.\n                          If there is an error any intermediate directories previously created are removed;\n                          note this makes this method unsafe for concurrent use\n:param groupingColumns: (java.lang.String[]) - List of columns the tables are grouped by (the write operation will store the grouping info)",
  "writeTable": "Write a table to a file.\n\n*Overload 1*  \n  :param sourceTable: (io.deephaven.db.tables.Table) - source table\n  :param destPath: (java.lang.String) - destination file path; the file name should end in \".parquet\" extension\n                      If the path includes non-existing directories they are created\n                      If there is an error any intermediate directories previously created are removed;\n                      note this makes this method unsafe for concurrent use\n  \n*Overload 2*  \n  :param sourceTable: (io.deephaven.db.tables.Table) - source table\n  :param destFile: (java.io.File) - destination file; the file name should end in \".parquet\" extension\n                      If the path includes non-existing directories they are created\n  \n*Overload 3*  \n  :param sourceTable: (io.deephaven.db.tables.Table) - source table\n  :param destFile: (java.io.File) - destination file; its path must end in \".parquet\".  Any non existing directories in the path are created\n                      If there is an error any intermediate directories previously created are removed;\n                      note this makes this method unsafe for concurrent use\n  :param definition: (io.deephaven.db.tables.TableDefinition) - table definition to use (instead of the one implied by the table itself)\n  \n*Overload 4*  \n  :param sourceTable: (io.deephaven.db.tables.Table) - source table\n  :param destFile: (java.io.File) - destination file; its path must end in \".parquet\".  Any non existing directories in the path are created\n                            If there is an error any intermediate directories previously created are removed;\n                            note this makes this method unsafe for concurrent use\n  :param writeInstructions: (io.deephaven.db.v2.parquet.ParquetInstructions) - instructions for customizations while writing\n  \n*Overload 5*  \n  :param sourceTable: (io.deephaven.db.tables.Table) - source table\n  :param destPath: (java.lang.String) - destination path; it must end in \".parquet\".  Any non existing directories in the path are created\n                            If there is an error any intermediate directories previously created are removed;\n                            note this makes this method unsafe for concurrent use\n  :param definition: (io.deephaven.db.tables.TableDefinition) - table definition to use (instead of the one implied by the table itself)\n  :param writeInstructions: (io.deephaven.db.v2.parquet.ParquetInstructions) - instructions for customizations while writing\n  \n*Overload 6*  \n  :param sourceTable: (io.deephaven.db.tables.Table) - source table\n  :param destFile: (java.io.File) - destination file; its path must end in \".parquet\".  Any non existing directories in the path are created\n                            If there is an error any intermediate directories previously created are removed;\n                            note this makes this method unsafe for concurrent use\n  :param definition: (io.deephaven.db.tables.TableDefinition) - table definition to use (instead of the one implied by the table itself)\n  :param writeInstructions: (io.deephaven.db.v2.parquet.ParquetInstructions) - instructions for customizations while writing",
  "writeTables": "Write out tables to disk.\n\n:param sources: (io.deephaven.db.tables.Table[]) - source tables\n:param tableDefinition: (io.deephaven.db.tables.TableDefinition) - table definition\n:param destinations: (java.io.File[]) - destinations"
 },
 "path": "io.deephaven.db.tables.utils.ParquetTools",
 "text": "Tools for managing and manipulating tables on disk in parquet format.",
 "typeName": "class"
}