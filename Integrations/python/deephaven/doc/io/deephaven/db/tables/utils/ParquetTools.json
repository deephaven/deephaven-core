{
 "className": "io.deephaven.db.tables.utils.ParquetTools",
 "methods": {
  "deleteTable": "Deletes a table on disk.\n\n:param path: (java.io.File) - path to delete",
  "readMultiFileTable": "**Incompatible overloads text - text from the first overload:**\n\nReads in a table from files discovered with locationKeyFinder using a definition built from the\n first location found, which must have non-null partition values for all partition keys.\n\n*Overload 1*  \n  :param locationKeyFinder: (io.deephaven.db.v2.locations.impl.TableLocationKeyFinder<io.deephaven.db.v2.locations.parquet.local.ParquetTableLocationKey>) - The source of location keys to include\n  :param readInstructions: (io.deephaven.db.v2.parquet.ParquetInstructions) - Instructions for customizations while reading\n  :param tableDefinition: (io.deephaven.db.tables.TableDefinition) - The table's definition\n  :return: (io.deephaven.db.tables.Table) The table\n  \n*Overload 2*  \n  :param locationKeyFinder: (io.deephaven.db.v2.locations.impl.TableLocationKeyFinder<io.deephaven.db.v2.locations.parquet.local.ParquetTableLocationKey>) - The source of location keys to include\n  :param readInstructions: (io.deephaven.db.v2.parquet.ParquetInstructions) - Instructions for customizations while reading\n  :return: (io.deephaven.db.tables.Table) The table",
  "readParquetSchemaAndTable": ":param source: java.io.File\n:param readInstructionsIn: io.deephaven.db.v2.parquet.ParquetInstructions\n:param instructionsOut: org.apache.commons.lang3.mutable.MutableObject<io.deephaven.db.v2.parquet.ParquetInstructions>\n:return: io.deephaven.db.tables.Table",
  "readTable": "**Incompatible overloads text - text from the first overload:**\n\nReads in a table from a file using the provided table definition.\n\n*Overload 1*  \n  :param sourceFilePath: (java.lang.String) - table location; the file should exist and end in \".parquet\" extension\n  :return: (io.deephaven.db.tables.Table) table\n  \n*Overload 2*  \n  :param sourceFilePath: (java.lang.String) - table location; the file should exist and end in \".parquet\" extension\n  :param readInstructions: (io.deephaven.db.v2.parquet.ParquetInstructions) - instructions for customizations while reading\n  :return: (io.deephaven.db.tables.Table) table\n  \n*Overload 3*  \n  :param sourceFile: (java.io.File) - table location; the file should exist and end in \".parquet\" extension\n  :return: (io.deephaven.db.tables.Table) table\n  \n*Overload 4*  \n  :param sourceFile: (java.io.File) - table location; the file should exist and end in \".parquet\" extension\n  :param readInstructions: (io.deephaven.db.v2.parquet.ParquetInstructions) - instructions for customizations while reading\n  :return: (io.deephaven.db.tables.Table) table\n  \n*Overload 5*  \n  :param sourceFilePath: (java.lang.String) - table location; the file should exist and end in \".parquet\" extension\n  :param definition: (io.deephaven.db.tables.TableDefinition) - table definition\n  :return: (io.deephaven.db.tables.Table) table\n  \n*Overload 6*  \n  :param sourceFilePath: (java.lang.String) - table location; the file should exist and end in \".parquet\" extension\n  :param definition: (io.deephaven.db.tables.TableDefinition) - table definition\n  :param readInstructions: (io.deephaven.db.v2.parquet.ParquetInstructions) - instructions for customizations while reading\n  :return: (io.deephaven.db.tables.Table) table\n  \n*Overload 7*  \n  :param sourceFile: (java.io.File) - table location; the file should exist and end in \".parquet\" extension\n  :param definition: (io.deephaven.db.tables.TableDefinition) - table definition\n  :return: (io.deephaven.db.tables.Table) table\n  \n*Overload 8*  \n  :param sourceFile: (java.io.File) - table location; the file should exist and end in \".parquet\" extension\n  :param definition: (io.deephaven.db.tables.TableDefinition) - table definition\n  :param readInstructions: (io.deephaven.db.v2.parquet.ParquetInstructions) - instructions for customizations while reading\n  :return: (io.deephaven.db.tables.Table) table",
  "setDefaultCompressionCodecName": ":param compressionCodecName: java.lang.String",
  "writeParquetTables": "Writes tables to disk in parquet format to a supplied set of destinations.  If you specify grouping columns, there\n must already be grouping information for those columns in the sources.  This can be accomplished with\n .by(<grouping columns>).ungroup() or .sort(<grouping column>).\n\n:param sources: (io.deephaven.db.tables.Table[]) - The tables to write\n:param tableDefinition: (io.deephaven.db.tables.TableDefinition) - The common schema for all the tables to write\n:param writeInstructions: (io.deephaven.db.v2.parquet.ParquetInstructions) - Write instructions for customizations while writing\n:param destinations: (java.io.File[]) - The destinations paths.    Any non existing directories in the paths provided are created.\n                        If there is an error any intermediate directories previously created are removed;\n                        note this makes this method unsafe for concurrent use\n:param groupingColumns: (java.lang.String[]) - List of columns the tables are grouped by (the write operation will store the grouping info)",
  "writeTable": "Write a table to a file.\n\n*Overload 1*  \n  :param sourceTable: (io.deephaven.db.tables.Table) - source table\n  :param destPath: (java.lang.String) - destination file path; the file name should end in \".parquet\" extension\n                   If the path includes non-existing directories they are created\n                   If there is an error any intermediate directories previously created are removed;\n                   note this makes this method unsafe for concurrent use\n  \n*Overload 2*  \n  :param sourceTable: (io.deephaven.db.tables.Table) - source table\n  :param destFile: (java.io.File) - destination file; the file name should end in \".parquet\" extension\n               If the path includes non-existing directories they are created\n  \n*Overload 3*  \n  :param sourceTable: (io.deephaven.db.tables.Table) - source table\n  :param destFile: (java.io.File) - destination file; its path must end in \".parquet\".  Any non existing directories in the path are created\n                   If there is an error any intermediate directories previously created are removed;\n                   note this makes this method unsafe for concurrent use\n  :param definition: (io.deephaven.db.tables.TableDefinition) - table definition to use (instead of the one implied by the table itself)\n  \n*Overload 4*  \n  :param sourceTable: (io.deephaven.db.tables.Table) - source table\n  :param destFile: (java.io.File) - destination file; its path must end in \".parquet\".  Any non existing directories in the path are created\n                   If there is an error any intermediate directories previously created are removed;\n                   note this makes this method unsafe for concurrent use\n  :param writeInstructions: (io.deephaven.db.v2.parquet.ParquetInstructions) - instructions for customizations while writing\n  \n*Overload 5*  \n  :param sourceTable: (io.deephaven.db.tables.Table) - source table\n  :param destPath: (java.lang.String) - destination path; it must end in \".parquet\".  Any non existing directories in the path are created\n                       If there is an error any intermediate directories previously created are removed;\n                       note this makes this method unsafe for concurrent use\n  :param definition: (io.deephaven.db.tables.TableDefinition) - table definition to use (instead of the one implied by the table itself)\n  :param writeInstructions: (io.deephaven.db.v2.parquet.ParquetInstructions) - instructions for customizations while writing\n  \n*Overload 6*  \n  :param sourceTable: (io.deephaven.db.tables.Table) - source table\n  :param destFile: (java.io.File) - destination file; its path must end in \".parquet\".  Any non existing directories in the path are created\n                   If there is an error any intermediate directories previously created are removed;\n                   note this makes this method unsafe for concurrent use\n  :param definition: (io.deephaven.db.tables.TableDefinition) - table definition to use (instead of the one implied by the table itself)\n  :param writeInstructions: (io.deephaven.db.v2.parquet.ParquetInstructions) - instructions for customizations while writing",
  "writeTables": "Write out tables to disk.\n\n:param sources: (io.deephaven.db.tables.Table[]) - source tables\n:param tableDefinition: (io.deephaven.db.tables.TableDefinition) - table definition\n:param destinations: (java.io.File[]) - destinations"
 },
 "path": "io.deephaven.db.tables.utils.ParquetTools",
 "text": "Tools for managing and manipulating tables on disk in parquet format.",
 "typeName": "class"
}